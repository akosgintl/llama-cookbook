{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42939a0f",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/meta-llama/llama-cookbook/blob/main/getting-started/Llama_4_Reasoning_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1e2cc",
   "metadata": {},
   "source": [
    "![Meta---Logo@1x.jpg](data:image/jpeg;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80395fc3-cc6e-4a1c-ad70-9d6f91bf6c95",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "\t<a href=\"https://llama.developer.meta.com/?utm_source=llama-cookbook&utm_medium=readme&utm_campaign=main\"><img src=\"https://img.shields.io/badge/Llama_API-Sign_up-4BA9FE?logo=meta\" /></a>\n",
    "\t<a href=\"https://llama.developer.meta.com/docs?utm_source=llama-cookbook&utm_medium=readme&utm_campaign=main\"><img src=\"https://img.shields.io/badge/Llama_API-Documentation-E4E6Eb?logo=meta\" /></a>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "\t<a href=\"https://github.com/meta-llama/llama-models/blob/main/models/?utm_source=llama-cookbook&utm_medium=readme&utm_campaign=main\"><img alt=\"Llama Model cards\" src=\"https://img.shields.io/badge/Llama-Model_cards-green?logo=meta\" /></a>\n",
    "\t<a href=\"https://www.llama.com/docs/overview/?utm_source=llama-cookbook&utm_medium=readme&utm_campaign=main\"><img alt=\"Llama Documentation\" src=\"https://img.shields.io/badge/Llama-Documentation-e4e6eb?logo=meta\" /></a>\n",
    "\t<a href=\"https://huggingface.co/meta-llama\"><img alt=\"Hugging Face meta-llama\" src=\"https://img.shields.io/badge/Hugging_Face-meta--llama-yellow?logo=huggingface\" /></a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f0082",
   "metadata": {},
   "source": [
    "# Running this notebook\n",
    "## API Keys\n",
    "1. Setup Llama API account and get an API key from the dashboard (https://llama.developer.meta.com/1296648131567215/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2106aa2-9777-4187-aadb-6d5eb59959da",
   "metadata": {},
   "source": [
    "# Notebook Outline\n",
    "In this notebook, we will explore the capabilities of Llama 4 Reasoning models: \n",
    "\n",
    "1. Overview of MoE architecture\n",
    "2. Llama API Model Usage\n",
    "3. Difference between Regular and Reasoning Models:\n",
    "    - Context Length\n",
    "    - Number of Experts\n",
    "4. Reasoning Tags & Parcing Reasoning Model output\n",
    "5. Prompting Reasoning Model with good samples for both text and image\n",
    "6. Using top-p, temperature, max_output_tokens\n",
    "7. Best practices\n",
    "8. Safety\n",
    "9. Hyperlink to using Llama API with reasoning Model if available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11fdb1d-be20-4ff0-93a2-8fb118748671",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Llama 4 models are natively multimodal, delivering best-in-class image and text capabilities. It's based in a Mixture-of-Experts (MoE) architecture and comprises two collections of models: Llama 4 Omni and Llama 4 Reasoning. The Omni model targets applications in multi image understanding, OCR, mulilingual agents, planning and tool use. The Reasoning model is best for challenging math, science and reasoning problems as well as coding assistant and STEM assistant.\n",
    "\n",
    "Both Llama 4 Omni and Llama 4 Reasoning support the same feature set, including:\n",
    "- Multilingual text input in [number-of-language] \n",
    "- Image understanding\n",
    "- TBD Tool calling\n",
    "- TBD Function calling\n",
    "- TBD Structured output in JSON format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb4a6e65-3d6d-4467-a52c-5105794e2049",
   "metadata": {},
   "source": [
    "# Llama4 MoE Architecture Overview\n",
    "Llama 4 uses a standard MoE and dense split across FFN and attention layers. Attention layers are the same as dense models - only the FFN layers have sparse parameters.\n",
    "<img src=\"../src/docs/img/Llama4_MoE_Architecture.png\" alt=\"\" style=\"display: block; margin: 0 auto;\" />\n",
    "Where the MoE layer has some routed experts and one shared expert. All tokens go through the shared expert.\n",
    "<img src=\"../src/docs/img/Llama4_MoE_Layer.png\" alt=\"\" style=\"display: block; margin: 0 auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6664fc98-f00f-4e64-a03e-46336541d909",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Llama 4 is a collection of 2 large language models (LLMs):\n",
    "\n",
    "#### Pretrained & Instruct Models:\n",
    "1. `llama 4 Omni` (text+multi image+speech(no OSS) input; text+speech(no OSS) output) - MoE with 16 expets\n",
    "1. `llama 17b Reasoning` (text+single image input; text output) - MoE with 16 routed expets and shared experts and capacity factor 1, 17B active parameters, 108B total parameters\n",
    "\n",
    "\n",
    "[Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md#instruction-tuned-models)    [TO DO: UPdate later]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dfa636-2e3b-4bc7-952d-161381b9d989",
   "metadata": {},
   "source": [
    "# Llama 4 Reasoning\n",
    "\n",
    "* *Open-source* \n",
    "* *Multimodal:* input: Text, Image(Single); Output: Text\n",
    "* *Language Support:* English Only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14534f5e-135d-4c05-a54d-237f83224033",
   "metadata": {},
   "source": [
    "## Getting Llama 4 Reasoning [TO DO: Update Later]\n",
    "\n",
    "Large language models are deployed and accessed in a variety of ways, including:\n",
    "\n",
    "1. **Self-hosting**: Using local hardware to run inference. Ex. running Llama on your Macbook Pro using [llama.cpp](https://github.com/ggerganov/llama.cpp) or running inference with lightweight models in both [Android](https://github.com/pytorch/executorch/blob/main/examples/demo-apps/android/LlamaDemo/docs/delegates/xnnpack_README.md) and [iOS](https://github.com/pytorch/executorch/blob/main/examples/demo-apps/apple_ios/LLaMA/docs/delegates/xnnpack_README.md) using the [PyTorch ExecuTotch](https://github.com/pytorch/executorch) framework.\n",
    "1. **Cloud hosting**: Using a cloud provider to deploy a model. Ex. AWS, Azure, GCP, and others.\n",
    "1. **Hosted API**: Llama API as a service. Ex. AWS Bedrock, Replicate, Anyscale, Groq, Together and others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad1085-58ef-4e68-bb9b-bbc562a0196c",
   "metadata": {},
   "source": [
    "### Hosted APIs\n",
    "\n",
    "Hosted APIs are the easiest way to get started. We'll use them here. As an example, we'll call Llama 4  using [Llama API](https://llama.developer.meta.com/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598e09b-2055-4aba-9cc9-3cac80b8e058",
   "metadata": {},
   "source": [
    "## Notebook Setup\n",
    "\n",
    "To install prerequisites run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e150e71b-b612-4e1a-852b-19f205919d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d90969-1663-4c5c-87de-b43064df1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+ssh://git@github.com/facebookincubator/llama-api-python.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a106719-1dca-4024-b3af-dc128e672ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip list pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab05e73a-41bc-47b0-85b6-594002c1de28",
   "metadata": {},
   "source": [
    "# Prompting Llama 4 Reasoning Models\n",
    "\n",
    "Prompt engineering is using natural language to produce a desired response from a large language model (LLM).\n",
    "\n",
    "In this section, we'll focus on Llama 4 17B reasoning model. You'll first learn special tokens that are supported by Llama 4 for prompt formating, then learn how to perform over 10 interesting or practical LLM tasks, including:\n",
    "[TO DO: Update]\n",
    "1. Llama 4 Prompt Formatting Special Tokens\n",
    "1. Multimodal use-cases\n",
    "    * Image captioning/labeling\n",
    "    * Cooking/Shopping assistant\n",
    "    * Travel assistant\n",
    "1. Tool calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3334a1-83e9-4893-ba1f-ca48d99f83da",
   "metadata": {},
   "source": [
    "## Llama 4 Prompt Formatting Special Tokens\n",
    "Here is a list of special tokens that are supported by Llama 4:\n",
    "<!--\n",
    "* `<|begin_of_text|>`: Specifies the start of the prompt\n",
    "* `<|end_of_text|>`: Model will cease to generate more tokens. This token is generated only by the base models.\n",
    "* `<|header_start|>` and `<|header_end|>`: These tokens enclose the role for a particular message. The possible roles are: [system, user and assistant].\n",
    "* `<|eom|>`: End of message. A message represents a possible stopping point for execution where the model can inform the executor that a tool call needs to be made.\n",
    "* `<|eot|>`: End of turn. Represents when the model has determined that it has finished interacting with the user message that initiated its response.\n",
    "* `<|image_start|>` and `<|image_end|>`: These tokens enclose the image data in the prompt.\n",
    "* `<|patch|>`: This token represents a piece of the tile/\n",
    "* `<|tile_y_separator|>` and `<|tile_x_separator|>`: These tokens are used to separate the y and x tiles of an image\n",
    "* `<|image|>`: In the new architecture, this token now separates the regular sized image information from a downsized version of it that fits in a single tile.-->\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Token</th>\n",
    "    <th>Description</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>&lt;|begin_of_text|&gt;</td>\n",
    "    <td>Specifies the start of the prompt</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>&lt;|end_of_text|&gt;</td>\n",
    "    <td>Model will cease to generate more tokens. This token is generated only by the base models.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>&lt;|header_start|&gt; and &lt;|header_end|&gt;</td>\n",
    "    <td>These tokens enclose the role for a particular message. The possible roles are: [system, user and assistant].</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>&lt;|eom|&gt;</td>\n",
    "    <td>End of message. A message represents a possible stopping point for execution where the model can inform the executor that a tool call needs to be made.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>&lt;|eot|&gt;</td>\n",
    "    <td>End of turn. Represents when the model has determined that it has finished interacting with the user message that initiated its response.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>&lt;|image_start|&gt; and &lt;|image_end|&gt;</td>\n",
    "    <td>These tokens enclose the image data in the prompt.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>&lt;|patch|&gt;</td>\n",
    "    <td>This token represents a piece of the tile/</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>&lt;|tile_y_separator|&gt; and &lt;|tile_x_separator|&gt;</td>\n",
    "    <td>These tokens are used to separate the y and x tiles of an image</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>&lt;|image|&gt;</td>\n",
    "    <td>In the new architecture, this token now separates the regular sized image information from a downsized version of it that fits in a single tile.</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "[TO DO: Update the link later]\n",
    "[Prompt Format Documentation](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_2#-llama-3.2-vision-models-(11b/90b)-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34231379-21c9-4ff7-8a61-e7187cba08f8",
   "metadata": {},
   "source": [
    "## Initialize the Llama API (Replace with your API Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae3b78-ff67-491a-8079-a6311f948332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_api import LlamaAPI\n",
    "from llama_api._types import Omit\n",
    "\n",
    "\n",
    "client = LlamaAPI(\n",
    "    api_key=\"LLM|985490929915228|efFvO9IC864irmXBKxNR3JEV0kw\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hi how are you?\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I'\\''m just a language model, I don'\\''t have feelings or emotions like humans do, but I'\\''m functioning properly and ready to help with any questions or tasks you have! How can I assist you today?\",\n",
    "        \"stop_reason\": \"stop\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Can you imagine having feelings?\"\n",
    "      },\n",
    "    ],\n",
    "    max_completion_tokens=1024,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd27f752-9eef-4ac3-9976-70f92881c6be",
   "metadata": {},
   "source": [
    "## Find available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d6b90-3626-414b-a533-482aced3c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.list()\n",
    "for model in response:\n",
    "    print(model)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea793b59-0778-46ea-9687-437a7590d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set up logging to output debug-level information to the console.\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(levelname)s: %(message)s')\n",
    "\n",
    "def fetch_content_with_logging(url):\n",
    "    \"\"\"\n",
    "    Fetches the HTML content from the provided URL with additional logging for debugging.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL of the page to fetch.\n",
    "        \n",
    "    Returns:\n",
    "        str: The HTML content of the page if successful.\n",
    "        \n",
    "    Raises:\n",
    "        requests.RequestException: If the HTTP request fails.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                       \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                       \"Chrome/91.0.4472.124 Safari/537.36\"),\n",
    "        # You could add more headers if needed, e.g., Accept, Accept-Language, etc.\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        logging.debug(\"Attempting to fetch URL: %s\", url)\n",
    "        logging.debug(\"Using headers: %s\", headers)\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        \n",
    "        logging.debug(\"Received response with status code: %d\", response.status_code)\n",
    "        logging.debug(\"Sample content %s\", response.text[:1000])\n",
    "        # logging.debug(\"Response headers: %s\", response.headers)\n",
    "        \n",
    "        # This will raise an HTTPError for 400, 500, etc.\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        html = response.text\n",
    "        logging.debug(\"Successfully fetched content; content length: %d characters\", len(html))\n",
    "        return html\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        logging.error(\"Request failed with error: %s\", e)\n",
    "        \n",
    "        # If we have a response object, log part of its text for debugging.\n",
    "        if 'response' in locals() and response is not None:\n",
    "            content_preview = response.text[:500]  # print first 500 characters\n",
    "            logging.error(\"Response content preview: %s\", content_preview)\n",
    "        raise\n",
    "\n",
    "def parse_article(html):\n",
    "    \"\"\"\n",
    "    Parses the HTML content to extract the main text and images.\n",
    "    \n",
    "    The function uses BeautifulSoup to locate an <article> tag \n",
    "    (which is common for blog posts) and then extracts all paragraph\n",
    "    texts and image sources within that tag.\n",
    "    \n",
    "    Args:\n",
    "        html (str): The HTML content of the page.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple (text, images) where text is a string of concatenated\n",
    "               paragraph texts and images is a list of image URLs.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Attempt to locate the article element\n",
    "    article = soup.find('article')\n",
    "    \n",
    "    # Fallback: If no <article> is found, try looking for a common container class.\n",
    "    if article is None:\n",
    "        article = soup.find('body')\n",
    "    \n",
    "    if article is None:\n",
    "        print(\"Could not find the main article content.\")\n",
    "        return \"\", []\n",
    "    \n",
    "    # Extract all paragraphs within the article.\n",
    "    paragraphs = article.find_all('p')\n",
    "    text = \"\\n\".join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))\n",
    "    \n",
    "    # Extract all image URLs in the article.\n",
    "    images = []\n",
    "    for img in article.find_all('img'):\n",
    "        # Get the src attribute; sometimes images may have a 'data-src' attribute instead.\n",
    "        src = img.get(\"src\") or img.get(\"data-src\")\n",
    "        if src:\n",
    "            images.append(src)\n",
    "    \n",
    "    return text, images\n",
    "\n",
    "def print_article_content(text, images):\n",
    "    \"\"\"\n",
    "    Prints the extracted text and image URLs.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text content of the article.\n",
    "        images (list): A list of image URLs.\n",
    "    \"\"\"\n",
    "    print(\"=== Article Text ===\")\n",
    "    print(text)\n",
    "    print(\"\\n=== Article Images ===\")\n",
    "    for idx, img_url in enumerate(images):\n",
    "        print(f\"[{idx}] {img_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715aa6e-7572-4106-a0c5-9240b5d585ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.meta.com/blog/llama-4-multimodal-intelligence/\"\n",
    "try:\n",
    "    html_content = fetch_content_with_logging(url)\n",
    "    text_content, image_urls = parse_article(html_content)\n",
    "    print_article_content(text_content, image_urls)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f85a99-f6e6-4d4e-80c4-3f022762a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO 1: images directly from the CDN error out, need to download and convert to base64\n",
    "## TODO 2: create images content dynamically based on the image list generated by the parser.\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "              \"url\": \"https://images.unsplash.com/photo-1582538885592-e70a5d7ab3d3?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1770&q=80\"\n",
    "            }\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"Summarize this article and tell me something about the image: {text_content}\"\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "    ],\n",
    "    max_completion_tokens=4096,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86a0519-4d01-487f-b7bc-184ddcae6cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.completion_message.content.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd755cf6-0f68-4e01-963c-05939f8a96b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.llama.com/docs/model-cards-and-prompt-formats/llama4_omni/\"\n",
    "try:\n",
    "    html_content = fetch_content_with_logging(url)\n",
    "    text_content, image_urls = parse_article(html_content)\n",
    "    print_article_content(text_content, image_urls)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a54210e-666e-44e4-ae35-166a97488569",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(html_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc442d0-71a1-4698-83ab-7e3d3b13fb86",
   "metadata": {},
   "source": [
    "# STEM Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c865c7ac-6131-42bf-950f-5bde23588419",
   "metadata": {},
   "source": [
    "## Text input only question\n",
    "\n",
    "First, let's see how to use the Llama 4 reasoning model for text only input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd299361-e48a-4824-93ce-621f199ebf88",
   "metadata": {},
   "source": [
    "### Simple chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc88c4-c748-4926-8747-030845be7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "messages=[\n",
    "  {\"role\": \"user\", \"content\": \"Which number is bigger: 9.11 or 9.9?\"},\n",
    "],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49187ffc-073e-480d-88c0-4444a1f6c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected output: 1) 2 horses and 2 chickens\n",
    "#2) 3 goats and 1 chicken\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "# Modify messages below to define conversation history\n",
    "messages=[\n",
    "  {\"role\": \"user\", \"content\": \"A horse costs $50, a chicken costs $20, and a goat costs $40, you bought 4 animals for a total of $140. Which animals (and how many of each) did you buy?\",},\n",
    "],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7123b905-0d9f-45b1-9ad0-a76f56bc3c2d",
   "metadata": {},
   "source": [
    "To ask a follow up question, just add the first Llama response as \"assistant\" role's content, then the follow up question with the \"user\" role:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad5333-389e-4125-8760-c048d519f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    # Modify messages below to define conversation history\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"A horse costs $50, a chicken costs $20, and a goat costs $40, you bought 4 animals for a total of $140. Which animals (and how many of each) did you buy?\"},\n",
    "      response.completion_message,\n",
    "      {\"role\": \"user\", \"content\": \"what if a horse costs $60?\"},\n",
    "    ],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680c2dac-0a53-4ba4-bb1e-6d428e614951",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "messages=[\n",
    "    #{\"role\": \"system\", \"content\":\"You are a math professor, smart but cool.\"},\n",
    "  {\"role\": \"user\", \"content\": \"\"\" Background: A train traveling from Bucharest to Ploiesti (60 km distance) has the speed of 60 km/h. \n",
    "The train starts in Bucharest and travels until Ploiesti, once, only in this direction.\n",
    "A swallow, flying with 90 km/h, fly from Ploiesti to the moving train.\n",
    "When it reaches the train, the swallow flies back toward Ploiesti,\n",
    "ahead of the train. At Ploiesti turns again back and continues to fly back and forth \n",
    "(between the train approaching Ploiesti and Ploiesti) until the train reaches Ploiesti. \n",
    "The swallow will fly continously all the time the train is traveling from Bucharest to Ploiesti.\n",
    "Reasoning: Think step by step. Explain your reasoning.\n",
    "Question:\n",
    "How many kilometers will travel totally the swallow? \"\"\"},\n",
    "],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10befd4d-67c3-46d5-942a-d51026557fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Use all the digits [0-9] to make three numbers: x,y,z so that x+y=z\"\n",
    "\n",
    "# For example, a possible solution is: x = 26, y = 4987, and z = 5013. Another possible soultion: 752 + 346 = 1098. It uses all digits 0-9 and x + y = z.\n",
    "\n",
    "# Tweak this maybe it will work, currently it cannot find the answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec204c7-a783-4a83-af12-f72a2e91a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"Use all the digits [0-9] to make three numbers: x,y,z so that x+y=z\"},\n",
    "    ],\n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c7d2b-df54-4727-88bb-f96e4e411c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riddle: Name three things that are always coming, but never arrive.\n",
    "response = client.chat.completions.create(\n",
    "# Modify messages below to define conversation history\n",
    "messages=[\n",
    "  {\"role\": \"user\", \"content\": \"Name three things that are always coming, but never arrive.\"},\n",
    "],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874cb919-d3e1-4e40-9406-7f2389ec57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# NOT AN ACCEPTABLE ANSWER FROM Llama 4; SHOULD CHECK Llama 4 REASONING #####################################\n",
    "# Suppose you're on a game show, and you're given the choice of three doors: Behind one door is a gold bar; behind the others, rotten vegetables. You pick a door, say No. 1, and the host asks you, 'Do you want to pick door No. 2 instead?' What choice of door now gives you the biggest advantage?\n",
    "response = client.chat.completions.create(\n",
    "# Modify messages below to define conversation history\n",
    "messages=[\n",
    "  {\"role\": \"user\", \"content\": \"Suppose you're on a game show, and you're given the choice of three doors: Behind one door is a gold bar; behind the others, rotten vegetables. You pick a door, say No. 1, and the host asks you, 'Do you want to pick door No. 2 instead?' What choice of door now gives you the biggest advantage?\"},\n",
    "],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7230865f-b2db-469d-8448-8680c8cad8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A group of four people needs to cross a bridge at night. The bridge is very old and rickety. They have only one torch, and because it's nighttime, the torch is necessary to cross the bridge. Each person walks at a different speed:A takes 1 minute to cross,B takes 2 minutes,C takes 5 minutes, andD takes 10 minutes.What is the fastest time they can all get across the bridge?\n",
    "response = client.chat.completions.create(\n",
    "# Modify messages below to define conversation history\n",
    "messages=[\n",
    "  {\"role\": \"user\", \"content\": \"A group of four people needs to cross a bridge at night. The bridge is very old and rickety. They have only one torch, and because it's nighttime, the torch is necessary to cross the bridge. Each person walks at a different speed:A takes 1 minute to cross,B takes 2 minutes,C takes 5 minutes, andD takes 10 minutes.What is the fastest time they can all get across the bridge?\"},],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    max_tokens=2048,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143382d-71fa-4e18-82cd-622d5414a3be",
   "metadata": {},
   "source": [
    "## Multimodal use-cases\n",
    "Here we show how we can use Llama 4 to describe an image or asking questions about an image. We start with a local image. Let's first display the example image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf841f-5ca2-4dc5-a853-222c30d23845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "\n",
    "def display_local_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    plt.figure(figsize=(5,4), dpi=200)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as img:\n",
    "    return base64.b64encode(img.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568fc60-bc95-4035-a43f-c14681b86676",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_local_image(\"../src/docs/img/triangle.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f412d9f4-ba59-4391-8daf-5825819a1582",
   "metadata": {},
   "outputs": [],
   "source": [
    "base64_image = encode_image(\"../src/docs/img/triangle.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86baadb5-a2e6-401a-9608-e66cce748207",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": [\n",
    "      {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"If it is given that the triangle in this image is a right triangle with its 90 degree angle at the top, that this vertex is above the ground an amount $h$, and that the system as shown is in equilibrium, how can I determine the length of the base? How much is it?\"\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "          \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        }},      \n",
    "]}],\n",
    "    \n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef92b5-eba3-454d-a134-8e5ce30405ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_local_image(\"../src/docs/img/triangle_2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc88696-0d76-41dc-a10e-9fb598ffad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base64_image = encode_image(\"../src/docs/img/triangle_2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70fd70e-3315-43bf-bcaf-b85d9361f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": [\n",
    "      {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"Help me solve this, please.\"\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "          \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        }},      \n",
    "]}],\n",
    "\n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3463287-2229-4e95-9bd8-5d9b714d04b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Two Examples to add Tool calling: tool calling did not work as far as I tested!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cfe9b7-7537-486d-a6af-7acab98464a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "messages=[\n",
    "  {\"role\": \"user\", \"content\": \"I am trying to drive from Scottsdale to Honolulu. What’s the best route to take?\"},\n",
    "],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b2b875-ecd7-419d-8773-92e88a1823db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Expand above and next example to include function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0be66b-f65b-40bd-9059-e14fbf263ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not a good response from reasoning model; should check with other more general topics like gen AI\n",
    "# Find me all the blogs from Medium about Llama 3.2\n",
    "response = client.chat.completions.create(\n",
    "\n",
    "messages=[\n",
    "  {\"role\": \"user\", \"content\": \"Find me all the blogs from Medium about Llama 3.2\"},\n",
    "],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df634c14-6bf9-45b0-9678-de5ce72a7be4",
   "metadata": {},
   "source": [
    "# Financial Use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd8d8bd-30a2-4c0d-ae59-7f0103e2dd6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### HINT: It seems the OCR is not working as expected, \n",
    "display_local_image(\"../src/docs/img/meta_geographic_revenue_2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5cb0b-bb2b-46d1-843f-27f89f760761",
   "metadata": {},
   "source": [
    "We then need to convert the binary image data into a base64-encoded string, which is a way of representing binary data in an ASCII text format using 64 characters (letters, numbers, +, and /), and then decode the base64 byte string to UTF-8 so it can be easily passed or stored as plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597aaf12-8901-49c9-a37c-3dc13bc545f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base64_image = encode_image(\"../src/docs/img/meta_geographic_revenue_2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba003a9-da0b-4054-abdd-ad626f2cad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": [\n",
    "      {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"Given this image, generate python code to create a line plot that shows the revenue of Facebook by geographic region over time. Make sure the plot captures all the dates and revenues.\"\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "          \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        }},      \n",
    "]}],\n",
    "    \n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f9347-dfc4-4673-837f-4b15d2911cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the data\n",
    "data = {\n",
    "    'Date': [\n",
    "        'Dec 31 2022', 'Mar 31 2023', 'Jun 30 2023', 'Sep 30 2023',\n",
    "        'Dec 31 2023', 'Mar 31 2024', 'Jun 30 2024', 'Sep 30 2024',\n",
    "        'Dec 31 2024'\n",
    "    ],\n",
    "    'US & Canada': [\n",
    "        15636, 13048, 14422, 15190, 15824, 16847, 17609, 1801, 12000\n",
    "    ],\n",
    "    'Europe': [\n",
    "        9441, 8483, 8300, 9492, 9153, 9341, 9300, 9492, 11503\n",
    "    ],\n",
    "    'Asia-Pacific': [\n",
    "        6050, 5960, 6515, 6028, 7512, 7481, 7888, 8220, 10245\n",
    "    ],\n",
    "    'Rest of World': [\n",
    "        4251, 4573, 4667, 5036, 5268, 5854, 3217, 3292, 3739\n",
    "    ],\n",
    "    'Worldwide': [\n",
    "        49165, 32165, 28645, 31999, 34146, 40111, 36455, 39071, 40589\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a line plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(df['Date'], df['US & Canada'], label='US & Canada')\n",
    "plt.plot(df['Date'], df['Europe'], label='Europe')\n",
    "plt.plot(df['Date'], df['Asia-Pacific'], label='Asia-Pacific')\n",
    "plt.plot(df['Date'], df['Rest of World'], label='Rest of World')\n",
    "plt.plot(df['Date'], df['Worldwide'], label='Worldwide')\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Facebook Revenue by Geographic Region Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue (in $ millions)')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5972b4-b1bb-4828-85f9-cd3e7349173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi image understanding with Omni\n",
    "# Still not working correctly with numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89e737-1add-4832-a57d-6d46c4ee9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_local_image(\"../src/docs/img/meta_geographic_revenue_part1.png\")\n",
    "display_local_image(\"../src/docs/img/meta_geographic_revenue_part2.png\")\n",
    "display_local_image(\"../src/docs/img/meta_geographic_revenue_part3.png\")\n",
    "display_local_image(\"../src/docs/img/meta_geographic_revenue_part4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd7c3a7-63fc-4bb1-b49d-ebf8d0bd9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "base64_image_part1 = encode_image(\"../src/docs/img/meta_geographic_revenue_part1.png\")\n",
    "base64_image_part2 = encode_image(\"../src/docs/img/meta_geographic_revenue_part2.png\")\n",
    "base64_image_part3 = encode_image(\"../src/docs/img/meta_geographic_revenue_part3.png\")\n",
    "base64_image_part4 = encode_image(\"../src/docs/img/meta_geographic_revenue_part4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42225c89-144a-4af2-ae6f-b7f1d19524f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": [\n",
    "      {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"Given these 4 images, generate python code to create a line plot that shows the revenue of Facebook by geographic region over time. Make sure the plot captures all the dates and revenues.\"\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "          \"url\": f\"data:image/jpeg;base64,{base64_image_part1}\"\n",
    "        }},\n",
    "        {\n",
    "    \"type\": \"image_url\",\n",
    "    \"image_url\": {\n",
    "      \"url\": f\"data:image/jpeg;base64,{base64_image_part2}\"\n",
    "    }},\n",
    "    {\n",
    "    \"type\": \"image_url\",\n",
    "    \"image_url\": {\n",
    "      \"url\": f\"data:image/jpeg;base64,{base64_image_part3}\"\n",
    "    }},\n",
    "   {\n",
    "    \"type\": \"image_url\",\n",
    "    \"image_url\": {\n",
    "      \"url\": f\"data:image/jpeg;base64,{base64_image_part4}\"\n",
    "    }},     \n",
    "          \n",
    "      \n",
    "]}],\n",
    "    \n",
    "  model=\"Llama-4-17B-Instruct\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c8571-60d3-40ea-99a6-24290d4ae4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "data = {\n",
    "    'Date': ['Dec 31 2022', 'Mar 31 2023', 'Jun 30 2023', 'Sep 30 2023', 'Dec 31 2023', 'Mar 31 2024', 'Jun 30 2024', 'Sep 30 2024', 'Dec 31 2024'],\n",
    "    'Worldwide': [31154, 28101, 31498, 33643, 38706, 35635, 38329, 39885, 46783],\n",
    "    'Europe': [6904, 6269, 7268, 7721, 8327, 9135, 9358, 11154, 0], # Set Dec 31 2024 to 0 since there is no data\n",
    "    'Asia-Pacific': [5968, 5893, 6435, 6829, 7316, 7338, 7721, 8050, 9012],\n",
    "    'Rest of World': [3377, 3229, 3664, 4137, 4447, 4519, 4880, 5088, 5635]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a line plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(df['Date'], df['Worldwide'], label='Worldwide', marker='o')\n",
    "plt.plot(df['Date'], df['Europe'], label='Europe', marker='o')\n",
    "plt.plot(df['Date'], df['Asia-Pacific'], label='Asia-Pacific', marker='o')\n",
    "plt.plot(df['Date'], df['Rest of World'], label='Rest of World', marker='o')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Revenue by Geographic Region Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue (in $ millions)')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709499a-1974-4d01-a5e8-c767516405ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Change below use case to the RAG use case!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbf014-dc3c-4144-bf4c-4ba504241a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  # Modify messages below to define conversation history\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"Compare advertising revenue by user geography with revenue by user geography\"},\n",
    "      {\"role\": \"user\", \"content\": \"../src/docs/img/Earnings-Presentation-Q3-2024.pdf\"},],\n",
    "    \n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7a38e-8ec8-4275-bb1d-18db198944f4",
   "metadata": {},
   "source": [
    "For this question, use the payment schedule for the US’s Social Security system given in the figure. A worker had an ANNUAL average income of $45,000 over 35 years and retired at the full benefits age. This value is “real,” so you can assume inflation has no impact on the calculation. To the nearest dollar, what is this worker's Primary Insurance Amount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a902e7-851e-4880-87ba-4b9761ca83a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_local_image(\"../src/docs/img/PIA_AIME_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67446f18-da23-4b62-9918-65b5b0aacee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base64_image = encode_image(\"../src/docs/img/PIA_AIME_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe379b4-7425-42b3-9d3f-e1c63a011806",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  # Modify messages below to define conversation history\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": [\n",
    "      {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"For this question, use the payment schedule for the US’s Social Security system given in the figure. A worker had an ANNUAL average income of $45,000 over 35 years and retired at the full benefits age. This value is “real,” so you can assume inflation has no impact on the calculation. To the nearest dollar, what is this worker's Primary Insurance Amount?\"\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "          \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        }},      \n",
    "]}],\n",
    "    \n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5314842-078e-4181-9774-3333186435b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  # Modify messages below to define conversation history\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"\"\"A machine costing $3,000 must be replaced at the end of 8 years. The resale value of the machine at\n",
    "the time of replacement is $600. At what annual discount rate (compounded annually) would it be\n",
    "equally economical to use a similar machine costing $4,000 with a life of 8 years and a resale value of\n",
    "$1,900? (Assume that there is no taxes.)\n",
    "\"\"\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"\", \"stop_reason\": \"end_of_turn\"}\n",
    "    ],\n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675ff5c-bc67-431a-b78c-6807298bc078",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Legal Usecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca465ec-d089-43b5-850c-0851310f8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"As someone who moved here before Brexit, am I allowed to vote in the UK?\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"\", \"stop_reason\": \"end_of_turn\"}\n",
    "    ],\n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4114f-2663-49ff-ae03-ddde560e3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"\"\"Jane has been diagnosed with a rare form of cancer. She has undergone several rounds of chemotherapy and radiation therapy, but the cancer has not responded well to treatment. Her doctor, Dr. Smith, has recommended that she undergo a clinical trial using a new experimental treatment. The treatment involves the use of a novel immunotherapy drug that has shown promise in early-stage clinical trials.\n",
    "However, the clinical trial is being conducted by a pharmaceutical company, XYZ Inc., which has a history of aggressive marketing tactics and has been accused of prioritizing profits over patient safety. Jane is concerned about the potential risks of the treatment and wants to know more about the company'\\''s track record before making a decision.\n",
    "Meanwhile, Jane'\\''s insurance company, ABC Insurance, has informed her that they will only cover the costs of the treatment if she participates in the clinical trial. Jane is worried that if she doesn'\\''t participate in the trial, she will be left with significant medical bills.\n",
    "Jane'\\''s lawyer, Mr. Johnson, has advised her that she may have grounds for a lawsuit against XYZ Inc. if she can prove that the company has engaged in deceptive marketing practices or has prioritized profits over patient safety. However, Mr. Johnson also warns Jane that pursuing a lawsuit could be costly and time-consuming, and may not guarantee a favorable outcome.\n",
    "Question:\n",
    "Based on the above scenario, what are the key legal issues that Jane should consider before deciding whether to participate in the clinical trial?\"\"\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"\", \"stop_reason\": \"end_of_turn\"}\n",
    "    ],\n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c5854-f776-46e5-959f-03cdedc759be",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"\"\"I am a citizen of Iran and entered the United States on January 1, 2023, as a visitor (B2 visa) with an initial stay period of six months. On June 15, 2023, I submitted an application for a B2 visa extension to the U.S. Citizenship and Immigration Services (USCIS), requesting an additional six-month stay due to unforeseen family circumstances. While my extension application is pending, I received news that my mother in Iran has fallen critically ill and requires immediate attention. Faced with this emergency situation, I am considering departing the United States without waiting for the outcome of my extension application.\n",
    "Will my departure from the United States while my B2 visa extension application is pending be considered an overstay, potentially jeopardizing my future immigration prospects?\"\"\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"\", \"stop_reason\": \"end_of_turn\"}\n",
    "    ],\n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dc6213-1317-42d1-9078-7921e973a330",
   "metadata": {},
   "source": [
    "# Medical Usecases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef047c00-78c4-4ccc-b5cd-5488f743d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"Why is it so hard to make a vaccine against AIDS?\"},\n",
    "    ],\n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bf9874-6877-4924-965a-211285894e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_local_image(\"../src/docs/img/ROCO_21830.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49747052-fad5-44df-bf58-99363a41e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "base64_image = encode_image(\"../src/docs/img/ROCO_21830.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a969839-ac10-4a06-a5d2-4493f5ffdb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are an expert radiologist with ample experience in chest x-ray analysis and the common diseases they can assist in diagnosing on the lungs.\"},\n",
    "      {\"role\": \"user\", \"content\": [\n",
    "      {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"I want you to give me your diagnosis for the issue pointed out in the image. If you are unable to diagnosis please provide what information is missing so I can provide further information to improve the response.\"\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "          \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        }},      \n",
    "]}],\n",
    "    \n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922e366b-8e9a-40f1-83de-c6c4046ad264",
   "metadata": {},
   "source": [
    "Reference caption: \"Chest x-ray post-OLT: Pneumothorax ex-vacuo. Arrow indicates location of chest tube.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d2638-5cc3-40c3-9b25-c34ca70f38c4",
   "metadata": {},
   "source": [
    "USMLE Question: A 55-year-old male presents with sudden onset of severe chest pain radiating to his left arm. Which of the following is the most likely diagnosis?\n",
    "(A) Myocardial Infarction\n",
    "(B) Pericarditis\n",
    "(C) Aortic Dissection\n",
    "(D) Pulmonary Embolism\n",
    "(E) Angina\n",
    "\n",
    "Answer: A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d811c0-5f2f-41e4-9df8-51ac63f31864",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"\"\"A 55-year-old male presents with sudden onset of severe chest pain radiating to his left arm. Which of the following is the most likely diagnosis?\n",
    "(A) Myocardial Infarction\n",
    "(B) Pericarditis\n",
    "(C) Aortic Dissection\n",
    "(D) Pulmonary Embolism\n",
    "(E) Angina\n",
    "\"\"\"},\n",
    "    ],\n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cfc492-c845-41b7-b008-f73fef18c314",
   "metadata": {},
   "source": [
    "# Coding Assistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7ed2d-5446-40da-867e-06ca26ad335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a program to help me decipher the following message: \"Ifmq.nf.efdjqifs.uif.gpmmpxjoh.nfttbhf\" using a Caesar cipher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aca69c-f0ab-4111-8fd9-22f2cdf8025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  # Modify messages below to define conversation history\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"\"\"Create a program to help me decipher the following message: \"Ifmq.nf.efdjqifs.uif.gpmmpxjoh.nfttbhf\" using a Caesar cipher.\"\"\"},\n",
    "    ],\n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b823e1cb-ed2a-4a97-ab78-604a6b5f2d0f",
   "metadata": {},
   "source": [
    "#### Algorithm Explanation\n",
    "Prompt: \"Explain how the QuickSort algorithm works and provide a step-by-step example with the array [5, 3, 8, 4, 2].\"\n",
    "Use Case: Understand complex algorithms with practical examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ecea8-7a06-4860-a678-68de09bb9c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"Explain how the QuickSort algorithm works and provide a step-by-step example with the array [5, 3, 8, 4, 2].\"},\n",
    "    ],\n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aafb9b-e5e1-4203-a9e6-4325936132f3",
   "metadata": {},
   "source": [
    "#### Fixing Coding Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac208523-3634-4424-8282-30be01befdd6",
   "metadata": {},
   "source": [
    "People participating in a city run had to write down their names when starting and ending the race. We know that exactly one person didn't finish the race. This Python function is trying to find out the name of that person but it doesn't work. Fix it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccf9573-864a-4e2b-b9af-c2c855b9de78",
   "metadata": {},
   "source": [
    "```python\n",
    "def find_person(names):\n",
    "  freq = {}\n",
    "  # Calculate the frequency of each name\n",
    "  for name in names:\n",
    "    if name not in freq:\n",
    "      freq[name] = 0\n",
    "      freq[name] += 1\n",
    "  # Find the name that appears only once\n",
    "  for name in names:\n",
    "    if freq[name] == 1:\n",
    "      return name\n",
    "  return None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fea70c5-3d35-4364-91ed-fe76dd5cc9ad",
   "metadata": {},
   "source": [
    "Before sending it to the AI, let’s understand what’s wrong with the code.\n",
    "\n",
    "Since each person writes down their name when starting and finishing the race, this code is trying to solve the problem by finding the name that appears only once. Each person completing the race will write their name twice, while the one who doesn't complete it only writes it once. However, this code incorrectly assumes that all names are distinct.\n",
    "\n",
    "The correct answer is not the name with a frequency equal to 1 but the name with an odd frequency. So the solution is to replace the second for loop check if freq[name] == 1: by if freq[name] % 2 == 1 to find the name with odd frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56da929e-3997-466c-8c8e-1494d5faa455",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"People participating in a city run had to write down their names when starting and ending the race. We know that exactly one person didn'\\''t finish the race. This Python function is trying to find out the name of that person but it doesn'\\''t work. Fix it. def find_person(names):  freq = {}  # Calculate the frequency of each name  for name in names:    if name not in freq:      freq[name] = 0      freq[name] += 1  # Find the name that appears only once  for name in names:    if freq[name] == 1:      return name  return None\"},\n",
    "      \n",
    "    ],\n",
    "  model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "  temperature=0.6,\n",
    "  top_p=0.9,\n",
    "  extra_body={\n",
    "    'repetition_penalty':\n",
    "    1,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb1532-d362-45fe-b734-c2878a538f8f",
   "metadata": {},
   "source": [
    "Hint: The 3.3's answer is incorrect as it does not take indistinct names into account and does not work for this test case: # Test the Pythonic function\n",
    "start_names = [\"John\", \"Alice\", \"Charlie\", \"Charlie\"]\n",
    "end_names = [\"John\", \"Alice\", \"Charlie\"]\n",
    "print(find_person_pythonic(start_names, end_names))  # Output: Charlie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae49bb5-c33a-44a6-95c0-e13fc860647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_person(start_names, end_names):\n",
    "  \"\"\"\n",
    "  This function finds the name of the person who didn't finish the race.\n",
    "\n",
    "  Parameters:\n",
    "  start_names (list): List of names at the start of the race.\n",
    "  end_names (list): List of names at the end of the race.\n",
    "\n",
    "  Returns:\n",
    "  str: The name of the person who didn't finish the race, or None if no one is found.\n",
    "  \"\"\"\n",
    "  # Combine start and end names into one list\n",
    "  all_names = start_names + end_names\n",
    "\n",
    "  # Calculate the frequency of each name\n",
    "  freq = {}\n",
    "  for name in all_names:\n",
    "    if name not in freq:\n",
    "      freq[name] = 1\n",
    "    else:\n",
    "      freq[name] += 1\n",
    "\n",
    "  # Find the name that appears an odd number of times\n",
    "  for name, count in freq.items():\n",
    "    if count % 2 != 0:\n",
    "      return name\n",
    "\n",
    "  return None\n",
    "\n",
    "# Alternatively, you can use a more Pythonic way to solve this problem\n",
    "def find_person_pythonic(start_names, end_names):\n",
    "  \"\"\"\n",
    "  This function finds the name of the person who didn't finish the race.\n",
    "\n",
    "  Parameters:\n",
    "  start_names (list): List of names at the start of the race.\n",
    "  end_names (list): List of names at the end of the race.\n",
    "\n",
    "  Returns:\n",
    "  str: The name of the person who didn't finish the race, or None if no one is found.\n",
    "  \"\"\"\n",
    "  # Use a set to find the difference between start and end names\n",
    "  start_set = set(start_names)\n",
    "  end_set = set(end_names)\n",
    "\n",
    "  # The person who didn't finish is the one in start_set but not in end_set\n",
    "  diff_set = start_set - end_set\n",
    "\n",
    "  # Return the name if found, otherwise return None\n",
    "  return list(diff_set)[0] if diff_set else None\n",
    "\n",
    "# Test the function\n",
    "start_names = [\"John\", \"Alice\", \"Bob\", \"Charlie\"]\n",
    "end_names = [\"John\", \"Alice\", \"Charlie\"]\n",
    "print(find_person(start_names, end_names))  # Output: Bob\n",
    "\n",
    "# Test the Pythonic function\n",
    "start_names = [\"John\", \"Alice\", \"Bob\", \"Charlie\"]\n",
    "end_names = [\"John\", \"Alice\", \"Charlie\"]\n",
    "print(find_person_pythonic(start_names, end_names))  # Output: Bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5b668-39b4-4139-a837-46bcd4dba5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "start_names = [\"John\", \"Alice\", \"Bob\", \"Charlie\"]\n",
    "end_names = [\"John\", \"Alice\", \"Charlie\"]\n",
    "print(find_person(start_names, end_names))  # Output: Bob\n",
    "\n",
    "# Test the Pythonic function\n",
    "start_names = [\"John\", \"Alice\", \"Charlie\", \"Charlie\"]\n",
    "end_names = [\"John\", \"Alice\", \"Charlie\"]\n",
    "print(find_person_pythonic(start_names, end_names))  # Output: Charlie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d19ef-0cb4-4052-bc77-bcef092e9ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop a model to predict product demand based on sales data.\n",
    "response_model = client.chat.completions.create(\n",
    "# Modify messages below to define conversation history\n",
    "messages=[\n",
    "  {\"role\": \"user\", \"content\": \"Develop a model to predict product demand based on sales data.\"},\n",
    "],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "\n",
    "print(response_model.completion_message.content.answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03374081-5072-4a5c-9214-f2245ca7266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_python = client.chat.completions.create(\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"Develop a model to predict product demand based on sales data.\"},\n",
    "      {\"role\": \"assistant\", \"content\": response_model.choices[0].message.content},\n",
    "      {\"role\": \"user\", \"content\": \"Please provide the code in an executable python format (.py)\", \"stop_reason\": \"end_of_turn\"}\n",
    "    ],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "\n",
    "print(response_python.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a9c2d9-603f-418a-9f9f-8cf380a38166",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_python = client.chat.completions.create(\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"Develop a model to predict product demand based on sales data.\"},\n",
    "      {\"role\": \"assistant\", \"content\": response_model.choices[0].message.content},\n",
    "      {\"role\": \"user\", \"content\": \"Please provide the code in an executable python format (.py)\"},\n",
    "      {\"role\": \"assistant\", \"content\": response_python.choices[0].message.content},\n",
    "      {\"role\": \"user\", \"content\": \"Please write a code to create a synthetic data for sales_data and rewrite the provided Python code into a single executable .py file that includes the synthetic data generation, data preprocessing, model training, and evaluation. Ensure that the code is well-structured, readable, and can be executed directly in a Python environment; Please create a requirements.txt file that lists all the necessary Python packages required to run the sales data prediction model. Include instructions on how to install these packages using pip.\", \"stop_reason\": \"end_of_turn\"},\n",
    "    ],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "\n",
    "print(response_python.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d985cf6-218c-4da4-94fd-3f36adc489c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Check if the python code gets run with no error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f4144-6986-4487-bc65-1440b3ea4402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Change Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd8a609",
   "metadata": {},
   "source": [
    "# Resources\n",
    "1. [Getting started with Llama](https://www.llama.com/docs/get-started/)\n",
    "2. [Llama Vision Capabilities](https://www.llama.com/docs/how-to-guides/vision-capabilities/)\n",
    "3. [Llama Stack](https://github.com/meta-llama/llama-stack)\n",
    "4. [Llama Stack Apps](https://github.com/meta-llama/llama-stack-apps)\n",
    "5. [Llama Recipes](https://github.com/meta-llama/llama-recipes) (End to end demos)\n",
    "    * [Multi-Modal RAG](https://github.com/meta-llama/llama-recipes/tree/Multi-Modal-RAG-Demo/recipes/quickstart/Multi-Modal-RAG)\n",
    "    * [PDF to Podcast](https://github.com/meta-llama/llama-recipes/tree/main/recipes/quickstart/NotebookLlama)\n",
    "    * [Agents 101 & 201](https://github.com/meta-llama/llama-recipes/tree/main/recipes/quickstart/agents/Agents_Tutorial)\n",
    "6. [Meta Trust & Safety](https://github.com/meta-llama/PurpleLlama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b823141-beef-49b0-92b3-5dbe38285817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Change FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0791f73",
   "metadata": {},
   "source": [
    "# FAQ\n",
    "1. Does Llama 3.2 Vision model support multiple images?\n",
    "    * No\n",
    "1. Does Llama 3.2 Vision model support tool calling?\n",
    "    * `No`, when `<image>` tag is used. `Yes` when `<image>` tag is not used in the prompt. \n",
    "1. What is the maximum pixel you can use with Llama Vision model?\n",
    "    * 1120\n",
    "1. Why does the Llama 3.2 Vision models accept text-only inputs if it is a multimodal model?\n",
    "    * With text-only inputs, the Llama 3.2 Vision models function the same as the Llama 3.1 Text models, making them a drop-in replacement with added image understanding capabilities.\n",
    "1. How should I format prompts for the Llama 3.2 Vision models?\n",
    "    * Use the `<|image|>` tag to represent the image in the prompt. You need to pass in the image separately along with this prompt. The model encodes the image appropriately along with the rest of the text in the prompt.\n",
    "1. How important is the position of the `<|image|>` tag in the prompt?\n",
    "    * The position is crucial. The image must immediately precede the text query to ensure the model uses the correct image for reasoning, controlled by the cross-attention layer mask. For more examples and details, refer to the vision prompt format documentation.\n",
    "1. How does tool-calling work with the Llama Lightweight models?\n",
    "    * Tool-calling can be done by passing function definitions in the system prompt or user prompt. Unlike larger models, the lightweight models do not support built-in tools like Brave Search and Wolfram, only custom functions.\n",
    "1. How do I format function calls for tool-calling with these models?\n",
    "    * Function calls should be formatted in the system or user prompt, using JSON format for function definitions. The model will respond with the appropriate function call based on the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbfbe0c-c20a-4fa5-b835-ce24162e232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool calling test\n",
    "# did not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67bf42d-be3f-4657-a251-86228d1a666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "# Modify messages below to define conversation history\n",
    "messages=[\n",
    "  {\"role\": \"user\", \"content\": \"Recommend the best place in USA I can go to hot air balloon festival, put event name, its city and month in JSON format output only\",},\n",
    "],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "\n",
    "print(response.completion_message.content.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f2ec87-1f16-47ad-9827-e0eef3e706f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_python = client.chat.completions.create(\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"Recommend the best place in USA I can go to hot air balloon festival, put event name, its city and month in JSON format output only\"},\n",
    "               {\n",
    "      \"role\": \"system\",\n",
    "      \"content\":  f\"\"\"\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "\"\"\"\n",
    "      },\n",
    "      {\"role\": \"assistant\", \"content\": response_model.choices[0].message.content},\n",
    "\n",
    "      {\"role\": \"user\", \"content\": \"Search to validate if the event {name} takes place in the {city} value in {month} value, replace {name}, {city} and {month} with values from {result}\"},\n",
    "      ],\n",
    "    model=\"dev-llama-4-17B-reasoning-latest\",\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    extra_body={\n",
    "      'repetition_penalty':\n",
    "      1,\n",
    "    }\n",
    "  )\n",
    "\n",
    "print(response_python.completion_message.content.answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
